{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Definitivo.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPEqKr0cirlJWAMIhg9pqca"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZJRbbSvwyLTA"},"source":["import numpy as np #Processamiento numérico\n","import scipy as sc #Amplia numpy\n","import matplotlib.pyplot as plt #Para dibujar\n","import time \n","\n","#Los datos para el primer ejemplo\n","from sklearn.datasets import make_circles #Dataset\n","\n","#Los datos para los números\n","from sklearn.datasets import fetch_openml\n","mnist = fetch_openml('mnist_784', cache=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LX96tr2x345"},"source":["#CLASSE DE LA CAPA DE LA RED\n","\n","class neural_layer():\n","  #Especificar número de conexiones. Núméro de neuronas. Función de activación.\n","  def __init__(self,n_conn, n_neur,act_f):\n","    self.act_f=act_f\n","    self.b = np.random.rand(1, n_neur)      *2-1 #Vector columna\n","    self.W = np.random.rand(n_conn, n_neur) *2-1 #Para que el random pase de 0,1 a -1,1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPPknaLEyDm7"},"source":["#FUNCIONES DE ACTIVACIÓN\n","\n","#lambda para indicar función anónima\n","sign = (lambda x: 1 / (1 + np.e**(-x)),\n","        lambda x: x*(1-x))\n","\n","_x = np.linspace(-5,5,100) #100 índices entre -5,5 para dibujar la función.\n","plt.plot(_x,sign[0](_x)) #El índice nos permite elegir si entrar a la derivada o a la función original."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4fFiOFKyG8J"},"source":["#FUNCIÓN ENCARGADA DE CREAR LA RED NEURONAL\n"," \n","def create_nn(topology, act_f):\n","  nn = []\n","  for i,layer in enumerate(topology[:-1]): #Para evitar overflow.\n","    nn.append(neural_layer(topology[i],topology[i+1],act_f))\n","  return nn\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d658thM5yyhw"},"source":["#FUNCIÓN ENCARGADA DE ENTRENAR LA RED NEURONAL\n","l2_cost = (lambda Yp,Yr : np.mean((Yp-Yr)**2), #Error cuadrático medio.\n","           lambda Yp,Yr : (Yp-Yr)) #La derivada del error.\n","\n","#X datos de entrada; Y datos de salid; Definidos al inicio.\n","def train(neural_net, X, Y, cost, lr=0.5, train = True): #0.5 learning rate que nos permite saber en que grado actualizamos. Demasiado grande puede hacer saltos. Pequeño que sea demasiado lento.\n","  out = [(None,X)] #Guardaremos tanto el valor de la suma ponderada como el de activación.\n","  \n","  #Forward pass: ir pasando el vector de entrada capa por capa.\n","  for l,layer in enumerate(neural_net):\n","\n","\n","    z = out[-1][1] @ neural_net[l].W + neural_net[l].b #Producto matricial.\n","    a = neural_net[0].act_f[0](z)\n"," \n","    out.append((z,a))\n","  \n","  if train:\n","    #Backward pass\n","    deltas = [] \n","\n","    for i in reversed(range(0, len(neural_net))):\n","\n","      z = out[i+1][0]\n","      a = out[i+1][1]\n","      \n","      #Miramos si estamos en la última capa\n","      if (i==len(neural_net)-1):\n","        deltas.insert(0,cost[1](a,Y)*neural_net[i].act_f[1](a))\n","      else:\n","        deltas.insert(0, deltas[0] @ _W.T * neural_net[i].act_f[1](a))\n","\n","      #Guardamos temporalmente la W que será la siguiente en la próxima iteración.\n","      _W = neural_net[i].W\n","\n","      #Gradient descent || NOS ESTAMOS REFERIENDO A LOS ÍNDICES DE LA CAPA ANTERIOR\n","      neural_net[i].b = neural_net[i].b - np.mean(deltas[0], axis = 0, keepdims = True)*lr\n","      neural_net[i].W = neural_net[i].W - out[i][1].T@deltas[0] *lr \n","\n","  return out[-1][1]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RcHsCRKfy5xG"},"source":["#EJEMPLO 2D sencillo\n","\n","n = 500 #Número de registros en la base de datos.\n","p = 2 #Características sobre cada dato.\n","o = 1 #Número de salidas\n","\n","#Creamos el dataset\n","X,Y=make_circles(n_samples=n,factor=0.5, noise=0.05) #Factor distancia entre circulos.\n","Y = Y[:,np.newaxis]\n","#X nos indica posición.\n","#Y nos indica a que set de datos pertenece. En este caso es true i false para indicar el circulo exterior o interior.\n","\n","plt.scatter(X[Y[:,0]==0,0],X[Y[:,0]==0,1], c= \"skyblue\")\n","plt.scatter(X[Y[:,0]==1,0],X[Y[:,0]==1,1], c=\"salmon\")\n","plt.axis(\"equal\") #Para que sea escala cuadrada\n","plt.show()\n","print(\"X: \",X.shape, \"Y: \",Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o37HMucLzLhX"},"source":["from IPython.display import clear_output\n","\n","topology = [p,8,4,1] #Última capa una neurona de salida. Elegido de forma arbitraria el número.\n","\n","neural_n = create_nn(topology, sign)\n","loss = []\n","\n","for i in range(1000):\n","  #Entrenamos la red\n","  pY = train(neural_n,X,Y,l2_cost,0.05)\n","\n","  #Printeamos cada 100 iteraciones\n","  if i%100 == 0:\n","    loss.append(l2_cost[0](pY,Y))\n","    res = 50\n","    _x0 = np.linspace(-1.5,1.5,res)\n","    _x1 = np.linspace(-1.5,1.5,res)\n","\n","    _Yshow = np.zeros((res,res))\n","\n","    for i0,x0 in enumerate(_x0):\n","      for i1,x1 in enumerate (_x1):\n","        _Yshow[i0,i1] = train(neural_n,np.array([[x0,x1]]),Y, l2_cost,train=False)[0][0]\n","    \n","    plt.pcolormesh(_x0,_x1,_Yshow,cmap=\"coolwarm\")\n","    plt.axis(\"equal\")\n","\n","    plt.scatter(X[Y[:,0]==0,0],X[Y[:,0]==0,1], c= \"skyblue\")\n","    plt.scatter(X[Y[:,0]==1,0],X[Y[:,0]==1,1], c= \"salmon\")\n","\n","    clear_output(wait=True)\n","    plt.show()\n","    plt.plot(range(len(loss)),loss)\n","    plt.show()\n","    time.sleep(0.5)\n","\n","print(loss)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-99T9sf2zy4V"},"source":["#EJEMPLO NÚMEROS\n","\n","n = 5000 #Número de registros en la base de datos.\n","p = 784 #Características sobre cada dato: corresponden a 28*28 píxeles\n","o = 1 #Número de salidas\n","\n","#Esta función nos sirve para imprimir el número de la base de datos por pantalla.\n","def dibuja(item):\n","  res = 28\n","  _x0 = np.linspace(0,1,res)\n","  #La y está invertida, porque\n","  _x1 = np.linspace(1,0,res)\n","\n","  plt.pcolormesh(_x0,_x1,item.reshape(res, res),cmap=\"Greys\")\n","  plt.axis(\"equal\")\n","  plt.show()\n","\n","#preprocesamos los datos de entrada para el entrenamiento de la red neuronal. Vamos a processar imágenes de 28*28 píxeles.\n","_X = mnist.data.astype('float32')\n","#los valores de cada pixel deben estar entre 0 y 1\n","_X /= 255.0\n","\n","#para la clasificación, cada vector de salida tendrá 10 números, una para cada dígito:\n","#esto se llama one hot encoding\n","_Y_int = mnist.target.astype('int64') #Esto són lo números.\n","Y = _Y_int[:n]\n","X = _X[:n,:] #Cogemos solo los que usaremos para entrenar\n","#Vamos a coger los diferentes Y para cada red neuronal.\n","\n","Y1 = np.copy(Y)\n","Y1 = Y1[:,np.newaxis]\n","for i, value  in enumerate(Y1):\n","  if value[0] <= 4:\n","    Y1[i][0] = 0.0\n","  else:\n","    Y1[i][0] = 1.0\n","\n","Y2 = np.copy(Y)\n","Y2 = Y2[:,np.newaxis]\n","for i, value  in enumerate(Y2):\n","  if value[0] % 2 == 0:\n","    Y2[i][0] = 0.0\n","  else:\n","    Y2[i][0] = 1.0\n","\n","Y3 = np.copy(Y)\n","Y3 = Y3[:,np.newaxis]\n","for i, value  in enumerate(Y3):\n","  if value[0] in (2,3,6,7,9):\n","    Y3[i][0] = 0.0\n","  else:\n","    Y3[i][0] = 1.0\n","\n","Y4 = np.copy(Y)\n","Y4 = Y4[:,np.newaxis]\n","for i, value  in enumerate(Y4):\n","  if value[0] in (2,3,4,8,9):\n","    Y4[i][0] = 0.0\n","  else:\n","    Y4[i][0] = 1.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-eI0AsYS8-eB"},"source":["#Comprobamos que esten bien los conjuntos\n","\n","check = []\n","values = [0,0,0,0,0,0,0,0,0,0]\n","for i in range(100):\n","  if Y[i] not in check:\n","    check.append(Y[i])\n","    values[Y[i]]=i\n","\n","for i in range(10):\n","  j = values[i]\n","  print(\"REAL: \", Y[j], \"A les diferents llistes: \",Y1[j],\" \",Y2[j],\" \",Y3[j],\" \",Y4[j])\n","\n","#La Lista 1 o Y1 es la primera columna del print etc."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MCC5um7OzTUX"},"source":["#RED1\n","print(\"RED1\")\n","c1=196\n","c2=40\n","reps = 5001\n","\n","topology1 = [p,c1,c2,o] #Última capa una neurona de salida. Elegido de forma arbitraria el número.\n"," \n","neural_n1 = create_nn(topology1, sign)\n","loss = []\n","timeA = time.time()\n","for i in range(reps):\n","  #Entrenamos la red\n","  pY = train(neural_n1,X,Y1,l2_cost,0.001)\n","  #Printeamos cada 100 iteraciones\n","  if i%100 == 0:\n","    loss.append(l2_cost[0](pY,Y1))\n","    print(\"Iteración número \",i,\" valor \",loss[-1], \" y ha trigat \", time.time() - timeA)\n","    timeA = time.time()\n","\n","#RED2\n","print(\"RED2\")\n","\n","topology2 = [p,c1,c2,o] #Última capa una neurona de salida. Elegido de forma arbitraria el número.\n"," \n","neural_n2 = create_nn(topology2, sign)\n","loss = []\n","timeA = time.time()\n","for i in range(reps):\n","  #Entrenamos la red\n","  pY = train(neural_n2,X,Y2,l2_cost,0.001)\n","  #Printeamos cada 100 iteraciones\n","  if i%100 == 0:\n","    loss.append(l2_cost[0](pY,Y2))\n","    print(\"Iteración número \",i,\" valor \",loss[-1], \" y ha trigat \", time.time() - timeA)\n","    timeA = time.time()\n","\n","#RED3\n","print(\"RED3\")\n","\n","topology3 = [p,c1,c2,o] #Última capa una neurona de salida. Elegido de forma arbitraria el número.\n"," \n","neural_n3 = create_nn(topology3, sign)\n","loss = []\n","timeA = time.time()\n","for i in range(reps):\n","  #Entrenamos la red\n","  pY = train(neural_n3,X,Y3,l2_cost,0.001)\n","  #Printeamos cada 100 iteraciones\n","  if i%100 == 0:\n","    loss.append(l2_cost[0](pY,Y3))\n","    print(\"Iteración número \",i,\" valor \",loss[-1], \" y ha trigat \", time.time() - timeA)\n","    timeA = time.time()\n","\n","#RED4\n","print(\"RED4\")\n","\n","topology4 = [p,c1,c2,o] #Última capa una neurona de salida. Elegido de forma arbitraria el número.\n"," \n","neural_n4 = create_nn(topology4, sign)\n","loss = []\n","timeA = time.time()\n","for i in range(reps):\n","  #Entrenamos la red\n","  pY = train(neural_n4,X,Y4,l2_cost,0.001)\n","  #Printeamos cada 100 iteraciones\n","  if i%100 == 0:\n","    loss.append(l2_cost[0](pY,Y4))\n","    print(\"Iteración número \",i,\" valor \",loss[-1], \" y ha trigat \", time.time() - timeA)\n","    timeA = time.time()\n","print(loss)\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NaxnmGRVFxL0"},"source":["#Usa las 4 redes neuronales para saber que número és\n","def WhatNum(nnet1,nnet2,nnet3,nnet4,image):\n","  prob = [1.,1.,1.,1.,1.,1.,1.,1.,1.,1.]\n","  set1 = train(nnet1,image,Y1,l2_cost,0.001,False)[0][0]\n","  set2 = train(nnet2,image,Y2,l2_cost,0.001,False)[0][0]\n","  set3 = train(nnet3,image,Y3,l2_cost,0.001,False)[0][0]\n","  set4 = train(nnet4,image,Y4,l2_cost,0.001,False)[0][0]\n","  if set1>=0.5:\n","    set1=0.9\n","  else:\n","   set1 = 0.1\n","  if set2>=0.5:\n","    set2=0.9\n","  else:\n","   set2 = 0.1\n","  if set3>=0.5:\n","    set3=0.9\n","  else:\n","   set3 = 0.1\n","  if set4>=0.5:\n","    set4=0.9\n","  else:\n","   set4 = 0.1\n","\n","\n","  for i in range(10):\n","    if i>4:\n","      prob[i]=prob[i]*set1\n","    else:\n","      prob[i]=prob[i]*(1-set1)\n","    if i%2==0:\n","      prob[i]=prob[i]*(1-set2)\n","    else: \n","      prob[i]=prob[i]*set2\n","    if i in (1,4,5,8,0):\n","      prob[i]=prob[i]*set3\n","    else:\n","      prob[i]=prob[i]*(1-set3)\n","    if i in (0,1,5,6,7):\n","      prob[i]=prob[i]*set4\n","    else:\n","      prob[i]=prob[i]*(1-set4)\n","\n","\n","  numberP = -10\n","  suposedN = 11\n","\n","  for i in range(10):\n","    if(prob[i]>numberP):\n","      numberP = prob[i]\n","      suposedN = i\n","  return suposedN\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DszuT61Zqps_"},"source":["asserts = 0\n","for i in range(10000):\n","  position = 5000+i\n","  num = _X[position]\n","  numS = num[:,np.newaxis]\n","  numS = numS.T\n","  suposed = WhatNum(neural_n1,neural_n2,neural_n3,neural_n4,numS)\n","  real = _Y_int[position]\n","  if(suposed==real):\n","    asserts+=1\n","\n","print(\"Assert rate: \", asserts/10000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHYUd95oz9ur"},"source":["position = 1009\n","num = _X[position]\n","numS = num[:,np.newaxis]\n","numS = numS.T\n","print(train(neural_n1,numS,Y1,l2_cost,0.001,False)[0][0])\n","dibuja(numS[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gs4rnkh84OOi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWaTznct0yET"},"source":[""],"execution_count":null,"outputs":[]}]}